{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and storage of the FISH images from the .lif files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images taken during the last FISH experiment (2020), on the SP8 Leica microscope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# To import the files\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# To read the images from the lif files\n",
    "import read_lif\n",
    "\n",
    "# To store the extracted data into a dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To plot the images\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Volumes/Seagate/eth/0_Leica_SP8/*/*.lif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "property_dict = dict()\n",
    "frame_dict = dict()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "for f in files:\n",
    "    reader = read_lif.Reader(f)\n",
    "    reader_name = f'{Path(f).parent.name}_{Path(f).name}'\n",
    "    series = reader.getSeries()\n",
    "    \n",
    "    for s in series:\n",
    "        channel_nbr = len(s.getChannels())\n",
    "        shape = s.getFrameShape()\n",
    "        nbr_frame = s.getNbFrames()\n",
    "        serie_name = s.getName()\n",
    "        \n",
    "        for c in range(channel_nbr):\n",
    "            channel = s.getFrame2D(channel=c)\n",
    "            \n",
    "            properties = [reader_name, serie_name, c, shape, nbr_frame]\n",
    "            property_dict.update({frame_count:properties})\n",
    "            frame_dict.update({frame_count:channel})\n",
    "            \n",
    "            \n",
    "            frame_count = frame_count+1\n",
    "            \n",
    "print(f'frame_count:{frame_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(property_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frame_dict.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the dictionnary into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(property_dict, orient='index', columns=['file', 'serie', 'channel', 'shape_ZXY', 'nbr_frames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md(s):\n",
    "    a = np.array(s)\n",
    "    return a[a>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['shape_ZXY'].apply(md).apply(pd.Series).rename(columns={0:'shape_X', 1:'shape_Y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df2, left_index=True, right_index=True).drop(['shape_ZXY'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shape_X'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['shape_Y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataframe to parquet\n",
    "df.to_parquet('parquets/image_information.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataframe parquet file:\n",
    "image_info = pd.read_parquet('parquets/image_information.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image storage to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_dict = image_info.groupby(['shape_X', 'shape_Y']).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shape_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = []\n",
    "image_array_lists = []\n",
    "\n",
    "for keys, values in shape_dict.items():\n",
    "    key_list.append(keys)\n",
    "    \n",
    "    image_arrays = []\n",
    "    for v in values:\n",
    "        image_arrays.append(frame_dict[v])\n",
    "    \n",
    "    image_array_lists.append(image_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(key_list):\n",
    "    np.save(f'image_arrays/{i}_images_{\"_\".join(tuple(map(str,k)))}.npy', image_array_lists[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that all the arrays have been saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_tot_arrays = 0\n",
    "\n",
    "for k in key_list:\n",
    "    nbr_tot_arrays = nbr_tot_arrays + len(shape_dict[k])\n",
    "    \n",
    "nbr_tot_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrays = glob.glob('image_arrays/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 0\n",
    "arrays = dict()\n",
    "\n",
    "for array in image_arrays:\n",
    "    name = Path(array).stem\n",
    "    arrays.update({name:np.load(array)})\n",
    "    \n",
    "    image_count = image_count + len(arrays[name])\n",
    "    \n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(arrays)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
