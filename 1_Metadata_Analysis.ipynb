{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the parquets and pickles files:\n",
    "          \n",
    "        - images_metadata.parquet                             --> Contains the metadata describing the channels and the dimensions for each images.\n",
    "        - attachments_metadata.pickle                         --> Used only to retrieved metadata relative to additional information on images, grouped in the DataFrames listed below.\n",
    "        - image_attachments_metadata.parquet                  --> Contains the metadata relative to the microscope model and software used.\n",
    "        - new_attachment_metadata.parquet                     --> Metadata left after sorting the metadata of interest: contains only 2 empty columns outside of the names and IDs columns.\n",
    "        - ATLConfocalSettingDefinition_metadata.parquet       --> Store the metadata relative to ATLConfocalSettingDefinition: Zoom, Pinhole, ...\n",
    "        - LDM_Block_Sequential_metadata.parquet               --> Store the metadata relative to LDM_Block_Sequential: Zoom, Pinhole, ...\n",
    "        - detector_information_metadata.parquet               --> Store information from ATLConfocalSettingDefinition referenced as Detector, Multiband and LUT.\n",
    "        - laser_information_metadata.pickle                   --> Store information from ATLConfocalSettingDefinition referenced as Laser, Shutter and Aotf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the dataframe\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword lists to clean the different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords specific to each categories:\n",
    "not_num_keywords = ['Name', 'TimeStamp', 'Model', 'ScanMode', 'Unit', 'Type', 'State', 'BeamPosition']\n",
    "\n",
    "integer_keywords = ['Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                    'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase']\n",
    "not_integer = ['Name', 'Position', 'Model', 'ScanMode', 'Unit', 'Can', 'Is']\n",
    "#'Type', 'Dimension'\n",
    "\n",
    "float_keywords = ['Min', 'Max', 'Bytes', 'Origin', 'Length', 'Position', 'Aperture', 'Index', 'Dim', 'Zoom', 'Pinhole', 'Time', 'Value', 'Range', 'CommonFactor', 'Gain', 'Offset', 'World', 'Power','Intensity']\n",
    "not_float = ['Dimension', 'ID', 'Name', 'Position', 'Model', 'ActiveCS']\n",
    "\n",
    "bool_keywords = ['CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "not_bool = ['Name', 'UseMode']\n",
    "#'Visibility', \n",
    "\n",
    "categorical_keywords = ['LUTName', 'LutName', 'DyeName', 'Detector.@Name', 'Detector.@Type', 'Detector.@ScanType', 'LaserName', 'LightSourceName', 'LightSourceType', '@Channel']\n",
    "not_cat = ['Tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe describing the channels and the dimension for each images\n",
    "dff_images = pd.read_parquet('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/images_metadata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images['FileName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images = dff_images.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter per dtype\n",
    "cols_num = list(filter(lambda x: [x for y in ['Min', 'Max', 'Bytes', 'Origin', 'Length', 'Position', 'Aperture', 'Index', 'Dim', 'Zoom', 'Pinhole', 'Time', 'Value', 'Range', 'CommonFactor', 'Gain', 'Offset', 'World', 'Power',\n",
    "                                              'Intensity',\n",
    "                                              'Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed','Direction', 'Wavelength', 'Average',\n",
    "                                              'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase',\n",
    "                                              'CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                  if y in x and 'Name' not in x and 'TimeStamp' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Type' not in x and 'State' not in x and 'BeamPosition' not in x],\n",
    "                       dff_images.columns.values))\n",
    "\n",
    "cols_integer = list(filter(lambda x: [x for y in ['Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                                                  'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase'] if y in x\n",
    "                                     and 'Name' not in x and 'Position' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Can' not in x and 'Is' not in x], dff_images.columns.values))\n",
    "\n",
    "cols_categ = list(filter(lambda x: [x for y in ['LUTName', 'LutName', 'DyeName', 'Detector.@Name', 'Detector.@Type', 'Detector.@ScanType', 'LaserName', 'LightSourceName', 'LightSourceType', '@Channel'] if y in x \n",
    "                                    and 'Tag' not in x], dff_images.columns.values))\n",
    "\n",
    "cols_bool = list(filter(lambda x: [x for y in ['CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                   if y in x and 'Name' not in x and 'UseMode' not in x],\n",
    "                        dff_images.columns.values))\n",
    "\n",
    "#cols_timeStamp = list(filter(lambda x: [x for y in ['TimeStamp'] if y in x and 'NumberOf' not in x], dff_images.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to float or int dtypes:\n",
    "for num in cols_num:\n",
    "    dff_images[num] = pd.to_numeric(dff_images[num], errors='coerce')\n",
    "\n",
    "# Conversion to booleen dtype:\n",
    "for b in cols_bool:\n",
    "    dff_images[b] = np.where(dff_images[b]==1, True, False)\n",
    "\n",
    "# Conversion to categorical dtype:\n",
    "dff_images[cols_categ] = dff_images[cols_categ].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special rule:\n",
    "\n",
    "# 'Visibility' cannot be used as keeyword for booleen:\n",
    "dff_images['@Visibility'] = np.where(dff_images['@Visibility']==1, True, False)\n",
    "\n",
    "# 'TimeStamp'is an excluded term for numerical values:\n",
    "dff_images['Data.Image.TimeStampList.@NumberOfTimeStamps'] = pd.to_numeric(dff_images['Data.Image.TimeStampList.@NumberOfTimeStamps'], errors='coerce')\n",
    "\n",
    "# Because the columns contains null-object:\n",
    "dff_images[cols_integer] = dff_images[cols_integer].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images['Dimension.@DimID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_images['Dimension.@NumberOfElements'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information relative to the microscope and the software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the metadata relative to the microscope and software\n",
    "dff_image_attachments = pd.read_parquet('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/image_attachments_metadata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_image_attachments.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special rule: integer contains the excluded keyword 'Type':\n",
    "cols_integer_2 = list(filter(lambda x: [x for y in ['Type'] if y in x and 'Name' not in x], dff_image_attachments.columns.values))\n",
    "\n",
    "for integer in cols_integer_2:\n",
    "    dff_image_attachments[integer] = pd.to_numeric(dff_image_attachments[integer], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_image_attachments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = dff_image_attachments.iloc[:,3:].values.ravel()\n",
    "pd.unique(all_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the files have been produced with the same microscope, the TCS SP8 confocal microscope.  \n",
    "Application:'LAS AF'  \n",
    "Software: 'LAS X 3.5.6.21594'  \n",
    "SystemTypeName: 'TCS SP8'  \n",
    "DataSourceTypeName: 'Confocal'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom, Pinhole, ...\n",
    "dff_ATLConfocalSettingDefinition = pd.read_parquet('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/ATLConfocalSettingDefinition_metadata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_ATLConfocalSettingDefinition.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_ATLConfocalSettingDefinition = dff_ATLConfocalSettingDefinition.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters for each categories:\n",
    "# Integers and floats are coupled together into the numeric category.\n",
    "\n",
    "cols_num_3 = list(filter(lambda x: [x for y in ['Min', 'Max', 'Bytes', 'Origin', 'Length', 'Position', 'Aperture', 'Index', 'Dim', 'Zoom', 'Pinhole', 'Time', 'Value', 'Range', 'CommonFactor', 'Gain', 'Offset', 'World', 'Power',\n",
    "                                                'Intensity',\n",
    "                                                'Resolution', 'DimID', 'NumberOfElements', 'Size', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Dimension', 'Speed',\n",
    "                                                'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Visibility', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase',\n",
    "                                                'CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                    if y in x and 'Name' not in x and 'TimeStamp' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Type' not in x and 'State' not in x and 'BeamPosition' not in x],\n",
    "                         dff_ATLConfocalSettingDefinition.columns.values))\n",
    "\n",
    "cols_integer_3 = list(filter(lambda x: [x for y in ['Resolution', 'DimID', 'NumberOfElements', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                    'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase'] if y in x\n",
    "                                     and 'Name' not in x and 'Position' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Can' not in x and 'Is' not in x],\n",
    "                             dff_ATLConfocalSettingDefinition.columns.values))\n",
    "\n",
    "cols_bool_3 = list(filter(lambda x: [x for y in ['CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                     if y in x and 'Name' not in x and 'UseMode' not in x],\n",
    "                        dff_ATLConfocalSettingDefinition.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to floats and integers:\n",
    "for num in cols_num_3:\n",
    "    dff_ATLConfocalSettingDefinition[num] = pd.to_numeric(dff_ATLConfocalSettingDefinition[num], errors='coerce')\n",
    "    \n",
    "# Conversion to booleen:\n",
    "for b in cols_bool_3:\n",
    "    dff_ATLConfocalSettingDefinition[b] = np.where(dff_ATLConfocalSettingDefinition[b]==1, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific rules:\n",
    "\n",
    "# Because the column name contains the excluded keyword 'Name':\n",
    "dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.@IsUserSettingNameSet'] = pd.to_numeric(dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.@IsUserSettingNameSet'], errors='coerce')\n",
    "dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.@IsUserSettingNameSet'] = np.where(dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.@IsUserSettingNameSet']==1, True, False)\n",
    "\n",
    "# Because the column name contains the excluded keyword 'Unit':\n",
    "dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.ClimateControl.@NumberOfUnits'] = pd.to_numeric(dff_ATLConfocalSettingDefinition['ATLConfocalSettingDefinition.ClimateControl.@NumberOfUnits'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the columns contains null-object:\n",
    "int_with_null_objects_3 = list(filter(lambda x: [x for y in ['ActiveCS_SubModeForRLD', 'Flip', 'Swap'] if y in x \n",
    "                                                 and 'Name' not in x and 'Position' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Can' not in x and 'Is' not in x],\n",
    "                                      dff_ATLConfocalSettingDefinition.columns.values))\n",
    "\n",
    "dff_ATLConfocalSettingDefinition[int_with_null_objects_3] = dff_ATLConfocalSettingDefinition[int_with_null_objects_3].astype('Int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_ATLConfocalSettingDefinition.info('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_detector_information = pd.read_parquet('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/detector_information_metadata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_detector_information = dff_detector_information.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters for each categories:\n",
    "# Integers and floats are coupled together into the numeric category.\n",
    "\n",
    "cols_num_4 = list(filter(lambda x: [x for y in ['Min', 'Max', 'Bytes', 'Origin', 'Length', 'Position', 'Aperture', 'Index', 'Dim', 'Zoom', 'Pinhole', 'Time', 'Value', 'Range', 'CommonFactor', 'Gain', 'Offset', 'World',\n",
    "                                                'Power','Intensity',\n",
    "                                                'Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                                                'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase',\n",
    "                                                'CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                    if y in x and 'Name' not in x and 'TimeStamp' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Type' not in x and 'State' not in x and 'BeamPosition' not in x],\n",
    "                         dff_detector_information.columns.values))\n",
    "\n",
    "cols_integer_4 = list(filter(lambda x: [x for y in ['Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                                                    'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase'] if y in x\n",
    "                                     and 'Name' not in x and 'Position' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Can' not in x and 'Is' not in x], \n",
    "                             dff_detector_information.columns.values))\n",
    "\n",
    "\n",
    "\n",
    "cols_bool_4 = list(filter(lambda x: [x for y in ['CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                     if y in x and 'Name' not in x and 'UseMode' not in x],\n",
    "                          dff_detector_information.columns.values))\n",
    "\n",
    "cols_categ_4 = list(filter(lambda x: [x for y in ['LUTName', 'LutName', 'DyeName', 'Detector.@Name', 'Detector.@Type', 'Detector.@ScanType', 'LaserName', 'LightSourceName', 'LightSourceType', '@Channel'] if y in x\n",
    "                                      and 'Tag' not in x], dff_detector_information.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to floats and integers:\n",
    "for num in cols_num_4:\n",
    "    dff_detector_information[num] = pd.to_numeric(dff_detector_information[num], errors='coerce')\n",
    "    \n",
    "# Conversion to booleen:\n",
    "for b in cols_bool_4:\n",
    "    dff_detector_information[b] = np.where(dff_detector_information[b]==1, True, False)\n",
    "\n",
    "# Conversion to category\n",
    "dff_detector_information[cols_categ_4] = dff_detector_information[cols_categ_4].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_detector_information.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information = pd.read_pickle('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/laser_information_metadata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information = dff_laser_information.fillna(pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters for each categories:\n",
    "# Integers and floats are coupled together into the numeric category.\n",
    "\n",
    "cols_num_5 = list(filter(lambda x: [x for y in ['Min', 'Max', 'Bytes', 'Origin', 'Length', 'Position', 'Aperture', 'Index', 'Dim', 'Zoom', 'Pinhole', 'Time', 'Value', 'Range', 'CommonFactor', 'Gain', 'Offset', 'World',\n",
    "                                                'Power','Intensity',\n",
    "                                                'Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                                                'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase',\n",
    "                                                'CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                    if y in x and 'Name' not in x and 'TimeStamp' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Type' not in x and 'State' not in x and 'BeamPosition' not in x],\n",
    "                         dff_laser_information.columns.values))\n",
    "\n",
    "cols_integer_5 = list(filter(lambda x: [x for y in ['Resolution', 'DimID', 'NumberOfElements', 'Size', 'Tag', 'Version', 'Bit', 'Mode', 'Section', 'Magnification', 'Pos', 'Number', 'Speed',\n",
    "                                                    'Direction', 'Wavelength', 'Average', 'Accumulation', 'Trigger', 'Relative', 'Detectors', 'Channels', 'Flip', 'Swap', 'Phase'] if y in x\n",
    "                                     and 'Name' not in x and 'Position' not in x and 'Model' not in x and 'ScanMode' not in x and 'Unit' not in x and 'Can' not in x and 'Is' not in x],\n",
    "                             dff_laser_information.columns.values))\n",
    "\n",
    "\n",
    "\n",
    "cols_bool_5 = list(filter(lambda x: [x for y in ['CanDo', 'Is', 'Use', 'Valid', 'Enable', 'InUse', 'CopyOption', 'AutoSelection', 'Keep', 'Normalize', 'Freq', 'Flag', 'OutChecked', 'OpenVirtual', 'ModeActive', 'TwoLaser']\n",
    "                                     if y in x and 'Name' not in x and 'UseMode' not in x], dff_laser_information.columns.values))\n",
    "\n",
    "cols_categ_5 = list(filter(lambda x: [x for y in ['LUTName', 'LutName', 'DyeName', 'Detector.@Name', 'Detector.@Type', 'Detector.@ScanType', 'LaserName', 'LightSourceName', 'LightSourceType', '@Channel'] if y in x\n",
    "                                      and 'Tag' not in x], dff_laser_information.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to floats and integers:\n",
    "for num in cols_num_5:\n",
    "    dff_laser_information[num] = pd.to_numeric(dff_laser_information[num], errors='coerce')\n",
    "    \n",
    "# Conversion to booleen:\n",
    "for b in cols_bool_5:\n",
    "    dff_laser_information[b] = np.where(dff_laser_information[b]==1, True, False)\n",
    "    \n",
    "# Conversion to category\n",
    "dff_laser_information[cols_categ_5] = dff_laser_information[cols_categ_5].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reconciliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique ID --> corresponding to unique image for all the files.\n",
    "dff_images['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique ID --> corresponding to unique image for all the files.\n",
    "dff_image_attachments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_image_attachments['Image.Attachment.Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 DataFrames `dff_image` and `dff_image_attachment` have the same number of `'Image.@UniqueID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both Dataframe on the Name of the files, the Image Names and the Image Unique IDs:\n",
    "dff_final = dff_images.merge(dff_image_attachments, how='outer', left_on=['FileName', 'Image.@Name', 'Image.@UniqueID'],\n",
    "                 right_on=['Image.Attachment.FileName', 'Image.Attachment.Image.@Name', 'Image.Attachment.Image.@UniqueID'],\n",
    "                 sort=False, suffixes=('Image.', 'Image.Attachment.'), indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the rows from dff_image_attachments have a counterpart in the dff_images:\n",
    "dff_final['_merge'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are the images that got 'left_only':\n",
    "dff_final[dff_final['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'left_only` occurs only when **no image** are present, which correspond to `200316_Sample_7.li` and `200304_200304_Rev10a2_GFP_Rods.lif`. Correspond to previous observation when retriving the xml data from the lif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the '_merge' column:\n",
    "dff_final.drop(['_merge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final[~(dff_final['FileName'] == dff_final['Image.Attachment.FileName']) & ~(dff_final['Image.@Name'] == dff_final['Image.Attachment.Image.@Name']) & ~(dff_final['Image.@UniqueID'] == dff_final['Image.Attachment.Image.@UniqueID'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merging seems to have been done correctly: in each row the FileName, ImageName and ImageUniqueID correspond between the two merged dataframe. Therefore we can drop the duplicate columns ('Image.Attachment.FileName', 'Image.Attachment.Image.@Name', 'Image.Attachment.Image.@UniqueID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns containing duplicated information:\n",
    "dff_final.drop(['Image.Attachment.FileName', 'Image.Attachment.Image.@Name', 'Image.Attachment.Image.@UniqueID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique ID --> corresponding to unique image for all the files.\n",
    "dff_ATLConfocalSettingDefinition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_ATLConfocalSettingDefinition['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 DataFrames `dff_image` and `dff_ATLConfocalSettingDefinition` have the same number of `'Image.@UniqueID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both Dataframe on the Name of the files, the Image Names and the Image Unique IDs:\n",
    "dff_final = dff_final.merge(dff_ATLConfocalSettingDefinition, how='outer', left_on=['FileName', 'Image.@Name', 'Image.@UniqueID'],\n",
    "                 right_on=['FileName', 'Image.@Name', 'Image.@UniqueID'], sort=False, suffixes=('Image.', 'ATLConfocalSettingDefinition.'),\n",
    "                            indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the rows from dff_image_attachments have a counterpart in the dff_images:\n",
    "dff_final['_merge'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are the images that got 'left_only':\n",
    "dff_final[dff_final['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'left_only` occurs only when **no image** are present, which correspond to `200316_Sample_7.li` and `200304_200304_Rev10a2_GFP_Rods.lif`. Correspond to previous observation when retriving the xml data from the lif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the '_merge' column:\n",
    "dff_final.drop(['_merge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique ID --> corresponding to unique image for all the files.\n",
    "dff_detector_information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_detector_information['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 DataFrames `dff_image` and `dff_detector_information` have the same number of `'Image.@UniqueID`. Several rows of information are available for each images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRow_dff_detector_information = dff_detector_information[dff_detector_information.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicateRow_dff_detector_information.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicated row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_detector_information.shape[0]/dff_detector_information['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both Dataframe on the Name of the files, the Image Names, the Image Unique IDs and the LutName column:\n",
    "dff_final = dff_final.merge(dff_detector_information, how='outer', left_on=['FileName', 'Image.@Name', 'Image.@UniqueID', 'Channel.@LUTName'],\n",
    "                 right_on=['FileName', 'Image.@Name', 'Image.@UniqueID', 'ATLConfocalSettingDefinition.LUT_List.LUT.@LutName'], sort=False, suffixes=('_Image', '_Detector'),\n",
    "                            indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the rows from dff_image_attachments have a counterpart in the dff_images:\n",
    "dff_final['_merge'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are the images that got 'left_only':\n",
    "dff_final[dff_final['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`200316_Sample_7.lif` and `200304_200304_Rev10a2_GFP_Rods.lif` doesn't have images.  \n",
    "\n",
    "**Missing data** for:  \n",
    "    - `200304_200304_Rev10a2_GFP_Lforms.lif`  / All images  \n",
    "    - `200304_200304_Test_Leica_SP8_2.lif`/ Image006 / Green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the '_merge' column:\n",
    "dff_final.drop(['_merge'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information.shape[0]/dff_laser_information['Image.@UniqueID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicateRow_4 = dff_laser_information[dff_laser_information.duplicated()]\n",
    "#duplicateRow_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [405, 458, 561, 800]\n",
    "dff_final['WaveLengths'] = pd.cut(dff_final['ATLConfocalSettingDefinition.Spectro.MultiBand.@TargetWaveLengthBegin'], bins=bins, labels=[405, 458, 561])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final['WaveLengths'] = dff_final['WaveLengths'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final['WaveLengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information['ATLConfocalSettingDefinition.LaserArray.Laser.@Wavelength'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_laser_information['ATLConfocalSettingDefinition.LaserArray.Laser.@Wavelength'] = dff_laser_information['ATLConfocalSettingDefinition.LaserArray.Laser.@Wavelength'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge both Dataframe on the Name of the files, the Image Names, the Image Unique IDs and the LutName column:\n",
    "dff_final = dff_final.merge(dff_laser_information, how='left', left_on=['FileName', 'Image.@Name', 'Image.@UniqueID', 'WaveLengths'],\n",
    "                 right_on=['FileName', 'Image.@Name', 'Image.@UniqueID', 'ATLConfocalSettingDefinition.LaserArray.Laser.@Wavelength'], sort=False, suffixes=('_Image', '_Laser'),\n",
    "                            indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all the rows from dff_image_attachments have a counterpart in the dff_images:\n",
    "dff_final['_merge'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are the images that got 'left_only':\n",
    "dff_final[dff_final['_merge'] == 'left_only']['WaveLengths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final[(dff_final['_merge'] == 'left_only') & (dff_final['WaveLengths'] == 405)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, problem for data of the files:  \n",
    "    - `200304_200304_Rev10a2_GFP_Lforms.li`  \n",
    "    - `200304_200304_Test_Leica_SP8_2.lif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final[(dff_final['Channel.@LUTName'] == 'Blue') & (dff_final['ATLConfocalSettingDefinition.LUT_List.LUT.@LutName'] == 'Blue') &(dff_final['ATLConfocalSettingDefinition.LaserArray.Laser.@Wavelength'] == 405)].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final.to_pickle('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/combined_metadata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dataframe = pd.read_pickle('/Users/virginie/bioformats/notebooks/metadata_leica_files/parquets_and_pickles/combined_metadata.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dataframe.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
